services:
  pyspark:
    build: .
    container_name: pyspark
    ports:
      - "8888:8888"   # Acc√®s au notebook Jupyter
      - "4040:4040"   # Interface Spark UI
    volumes:
      - ./pyspark:/home/dev
    environment:
      - PYSPARK_PYTHON=python3
      - PYSPARK_DRIVER_PYTHON=jupyter
      - PYSPARK_DRIVER_PYTHON_OPTS=notebook
    networks:
      - spark-network

  postgres:
    image: postgres:16.10-alpine3.22
    container_name: postgres
    restart: always
    shm_size: 128mb
    environment:
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: admin
      POSTGRES_DB: demo
    volumes:
      - pgdata:/var/lib/postgresql/data
      - ./data:/data
    ports:
      - "5432:5432"
    networks:
      - backend
  
  # adminer:
  #   image: adminer
  #   restart: always
  #   ports:
  #     - 8088:8088
  #   networks:
  #     - backend

  dbt:
    image: ghcr.io/dbt-labs/dbt-postgres:1.9.0
    container_name: dbt
    # build: .
    depends_on:
      - postgres
    working_dir: /usr/app
    volumes:
      - ./dbt_project:/usr/app
    environment:
      DBT_PROFILES_DIR: /usr/app
    entrypoint: ["sleep", "infinity"]
    # command: ["run"]
    networks:
      - backend
    tty: true

  # dbt-docs:
  #   image: ghcr.io/dbt-labs/dbt-postgres:1.9.0
  #   container_name: dbt-docs
  #   depends_on:
  #     - dbt
  #   working_dir: /usr/app
  #   volumes:
  #     - ./dbt_project:/usr/app
  #   environment:
  #     DBT_PROFILES_DIR: /usr/app
  #   entrypoint: ["sleep", "infinity"]
  #   # command: bash -c "dbt docs generate && dbt docs serve --port 8088 --host 0.0.0.0"
  #   ports:
  #     - "8088:8088"
  #   networks:
  #     - backend
  #   tty: true

volumes:
  pgdata:

networks:
  spark-network:
    driver: bridge
  backend: